from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import json
import os
from dotenv import load_dotenv
import google.generativeai as genai  # æ›¿æ¢ openai å¯¼å…¥

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é…ç½® Google Gemini
genai.configure(api_key=GOOGLE_API_KEY)  # ä½¿ç”¨ Google API key

# æä¾›é™æ€æ–‡ä»¶æœåŠ¡
@app.route('/')
def index():
    return send_from_directory('.', 'index.html')

@app.route('/<path:filename>')
def static_files(filename):
    return send_from_directory('.', filename)

# AIåˆ†ææ¥å£
@app.route('/api/analyze', methods=['POST'])
def analyze_content():
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        content = data.get('content', '').strip()
        
        if not content:
            return jsonify({'error': 'å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        # è°ƒç”¨AIåˆ†æå‡½æ•°
        analysis = analyze_with_ai(content)
        
        return jsonify({
            'success': True,
            'comments': analysis
        })
        
    except Exception as e:
        print(f'AIåˆ†æé”™è¯¯: {e}')
        return jsonify({
            'error': 'AIåˆ†æå¤±è´¥',
            'message': str(e)
        }), 500

# åˆ†æ®µåˆ†ææ¥å£
@app.route('/api/analyze-segment', methods=['POST'])
def analyze_segment():
    try:
        data = request.get_json()
        segment = data.get('segment', '').strip()
        context = data.get('context', [])
        
        if not segment:
            return jsonify({'error': 'åˆ†æ®µå†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        # è°ƒç”¨åˆ†æ®µåˆ†æå‡½æ•°
        analysis = analyze_segment_with_ai(segment, context)
        
        return jsonify({
            'success': True,
            'comments': analysis
        })
        
    except Exception as e:
        print(f'åˆ†æ®µåˆ†æé”™è¯¯: {e}')
        return jsonify({
            'error': 'åˆ†æ®µåˆ†æå¤±è´¥',
            'message': str(e)
        }), 500

# æœ€ç»ˆåˆ†ææ¥å£
@app.route('/api/analyze-final', methods=['POST'])
def analyze_final():
    try:
        data = request.get_json()
        full_content = data.get('fullContent', '').strip()
        segments = data.get('segments', [])
        
        if not full_content:
            return jsonify({'error': 'å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        # è°ƒç”¨æœ€ç»ˆåˆ†æå‡½æ•°
        analysis = analyze_final_with_ai(full_content, segments)
        
        return jsonify({
            'success': True,
            'comments': analysis
        })
        
    except Exception as e:
        print(f'æœ€ç»ˆåˆ†æé”™è¯¯: {e}')
        return jsonify({
            'error': 'æœ€ç»ˆåˆ†æå¤±è´¥',
            'message': str(e)
        }), 500

# AIå›åº”æ¥å£
@app.route('/api/respond', methods=['POST'])
def respond_to_question():
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        comment_id = data.get('commentId')
        response = data.get('response', '').strip()
        
        if not response:
            return jsonify({'error': 'å›ç­”å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        # è°ƒç”¨AIå›åº”å‡½æ•°
        feedback = respond_with_ai(response)
        
        return jsonify({
            'success': True,
            'content': feedback
        })
        
    except Exception as e:
        print(f'AIå›åº”é”™è¯¯: {e}')
        return jsonify({
            'error': 'AIå›åº”å¤±è´¥',
            'message': str(e)
        }), 500

def analyze_with_ai(content):
    """
    ä½¿ç”¨ Google Gemini Pro åˆ†æç”¨æˆ·è®²è§£å†…å®¹
    """
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªè®¤çœŸå­¦ä¹ çš„å­¦ç”Ÿã€‚è¯·åˆ†æè€å¸ˆçš„è¿™æ®µè®²è§£ï¼š

"{content}"

è¯·ä»¥å­¦ç”Ÿçš„è§’åº¦æå‡º2-4ä¸ªé—®é¢˜æˆ–æ‰¹æ³¨ï¼Œå¸®åŠ©å‘ç°è®²è§£ä¸­çš„ï¼š
1. ä¸æ¸…æ¥šçš„æ¦‚å¿µ
2. é€»è¾‘è·³è·ƒ
3. ç¼ºå°‘ä¾‹å­çš„åœ°æ–¹
4. éœ€è¦æ›´è¯¦ç»†è§£é‡Šçš„éƒ¨åˆ†

å¯¹äºé‡è¦çš„ç–‘é—®ï¼Œæ ‡è®°ä¸ºéœ€è¦è€å¸ˆå›åº”(needsResponse: true)ã€‚

ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "id": "q1",
    "type": "question",
    "title": "æ¦‚å¿µç–‘é—®", 
    "content": "å…·ä½“çš„é—®é¢˜å†…å®¹",
    "needsResponse": true
  }},
  {{
    "id": "q2",
    "type": "clarification", 
    "title": "éœ€è¦æ¾„æ¸…",
    "content": "éœ€è¦æ¾„æ¸…çš„å†…å®¹",
    "needsResponse": false
  }}
]

typeå¯ä»¥æ˜¯: question(ç–‘é—®), concern(æ‹…å¿§), clarification(æ¾„æ¸…), praise(å¥½è¯„)
needsResponse: å¦‚æœæ˜¯é‡è¦é—®é¢˜éœ€è¦è€å¸ˆè¯¦ç»†å›ç­”åˆ™ä¸ºtrueï¼Œä¸€èˆ¬æ€§è¯„è®ºä¸ºfalse
"""

    try:
        # åˆå§‹åŒ– Gemini Pro æ¨¡å‹
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # ç”Ÿæˆå›å¤
        response = model.generate_content(prompt)
        
        # è·å–æ–‡æœ¬å“åº”
        ai_response = response.text
        
        # å°è¯•è§£æJSONå“åº”
        try:
            return json.loads(ai_response)
        except json.JSONDecodeError:
            # å¦‚æœAIè¿”å›æ ¼å¼ä¸æ­£ç¡®ï¼Œæä¾›é»˜è®¤å“åº”
            return [
                {
                    "id": "q1",
                    "type": "question",
                    "title": "ç†è§£ç¡®è®¤",
                    "content": "æˆ‘å¯¹ä½ åˆšæ‰çš„è®²è§£æœ‰äº›ç–‘é—®ï¼Œèƒ½å¦å†è¯¦ç»†è§£é‡Šä¸€ä¸‹ï¼Ÿ",
                    "needsResponse": True
                }
            ]
            
    except Exception as e:
        print(f'Google Gemini APIè°ƒç”¨å¤±è´¥: {e}')
        # è¿”å›é»˜è®¤æ‰¹æ³¨
        return [
            {
                "id": "error",
                "type": "concern",
                "title": "ç³»ç»Ÿæç¤º",
                "content": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "needsResponse": False
            }
        ]

def respond_with_ai(user_response):
    """
    ä½¿ç”¨ Google Gemini Pro å¯¹ç”¨æˆ·çš„å›ç­”è¿›è¡Œåé¦ˆ
    """
    prompt = f"""
ä½œä¸ºä¸€ä¸ªå­¦ç”Ÿï¼Œæˆ‘åˆšåˆšå¬äº†è€å¸ˆå¯¹æˆ‘é—®é¢˜çš„å›ç­”ï¼š

"{user_response}"

è¯·ç»™å‡ºç®€çŸ­çš„åé¦ˆï¼Œè¡¨è¾¾ï¼š
1. å¯¹è§£ç­”çš„ç†è§£ç¨‹åº¦
2. æ˜¯å¦è¿˜æœ‰ç–‘é—®
3. æ„Ÿè°¢è€å¸ˆçš„è€å¿ƒè§£é‡Š

ç”¨ç®€æ´ã€è‡ªç„¶çš„è¯­è¨€å›å¤ï¼Œå°±åƒçœŸå®å­¦ç”Ÿä¼šè¯´çš„è¯ã€‚
"""

    try:
        # åˆå§‹åŒ– Gemini 2.5 Flash æ¨¡å‹
        model = genai.GenerativeModel('gemini-2.5-flash')

        # ç”Ÿæˆå›å¤
        response = model.generate_content(prompt)
        
        # è·å–æ–‡æœ¬å“åº”
        return response.text.strip()
            
    except Exception as e:
        print(f'Google Gemini APIè°ƒç”¨å¤±è´¥: {e}')
        # è¿”å›é»˜è®¤åé¦ˆ
        return "è°¢è°¢è€å¸ˆçš„è§£é‡Šï¼æˆ‘æ˜ç™½äº†å¾ˆå¤šã€‚"

def analyze_segment_with_ai(segment, context):
    """
    åˆ†æ®µåˆ†æç”¨æˆ·è®²è§£å†…å®¹
    """
    context_summary = ""
    if context:
        context_summary = f"ä¹‹å‰å·²ç»è®²è§£äº†{len(context)}ä¸ªéƒ¨åˆ†ï¼Œä¸»è¦æ¶‰åŠçš„è¯é¢˜æœ‰ï¼š"
        for i, seg in enumerate(context[-3:]):  # åªä¿ç•™æœ€è¿‘3æ®µçš„ä¸Šä¸‹æ–‡
            context_summary += f"\n{i+1}. {seg['content'][:50]}..."
    
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªè®¤çœŸå­¦ä¹ çš„å­¦ç”Ÿã€‚è€å¸ˆæ­£åœ¨åˆ†æ®µè®²è§£çŸ¥è¯†ç‚¹ã€‚

{context_summary}

ç°åœ¨è€å¸ˆè®²è§£äº†è¿™ä¸€æ®µï¼š
"{segment}"

ä½œä¸ºå­¦ç”Ÿï¼Œè¯·å¯¹è¿™ä¸€æ®µå†…å®¹æå‡º1-2ä¸ªç®€çŸ­çš„å®æ—¶åé¦ˆï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. è¿™æ®µå†…å®¹æ˜¯å¦æ¸…æ¥šæ˜“æ‡‚
2. æ˜¯å¦éœ€è¦ä¸¾ä¾‹è¯´æ˜
3. ä¸å‰é¢å†…å®¹çš„é€»è¾‘è¿æ¥
4. ç®€çŸ­çš„é¼“åŠ±æˆ–ç–‘é—®

ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "id": "seg1",
    "type": "question",
    "title": "å®æ—¶ç–‘é—®",
    "content": "å…·ä½“çš„é—®é¢˜å†…å®¹",
    "needsResponse": false
  }}
]

æ³¨æ„ï¼š
- åˆ†æ®µåˆ†æä¸»è¦æ˜¯å®æ—¶åé¦ˆï¼ŒneedsResponseé€šå¸¸ä¸ºfalse
- è¯„è®ºè¦ç®€çŸ­ï¼Œç¬¦åˆå®æ—¶è·Ÿè¿›çš„ç‰¹ç‚¹
- typeå¯ä»¥æ˜¯: question(ç–‘é—®), clarification(æ¾„æ¸…), praise(å¥½è¯„), concern(æ‹…å¿§)
"""

    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        ai_response = response.text
        
        try:
            return json.loads(ai_response)
        except json.JSONDecodeError:
            return [
                {
                    "id": "seg_default",
                    "type": "praise",
                    "title": "ç»§ç»­è®²è§£",
                    "content": "è¿™éƒ¨åˆ†è®²å¾—ä¸é”™ï¼Œè¯·ç»§ç»­ï¼",
                    "needsResponse": False
                }
            ]
            
    except Exception as e:
        print(f'åˆ†æ®µåˆ†æAPIè°ƒç”¨å¤±è´¥: {e}')
        return [
            {
                "id": "seg_error",
                "type": "concern",
                "title": "ç³»ç»Ÿæç¤º",
                "content": "å®æ—¶åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œç»§ç»­è®²è§£å³å¯ã€‚",
                "needsResponse": False
            }
        ]

def analyze_final_with_ai(full_content, segments):
    """
    æœ€ç»ˆç»¼åˆåˆ†æ
    """
    segment_summary = ""
    if segments:
        segment_summary = f"åœ¨è®²è§£è¿‡ç¨‹ä¸­ï¼Œæˆ‘å·²ç»å¯¹{len(segments)}ä¸ªéƒ¨åˆ†è¿›è¡Œäº†å®æ—¶åé¦ˆã€‚"
    
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªè®¤çœŸå­¦ä¹ çš„å­¦ç”Ÿã€‚è€å¸ˆåˆšåˆšå®Œæˆäº†ä¸€æ¬¡å®Œæ•´çš„çŸ¥è¯†è®²è§£ã€‚

{segment_summary}

å®Œæ•´çš„è®²è§£å†…å®¹æ˜¯ï¼š
"{full_content}"

ç°åœ¨è¯·ä½œä¸ºå­¦ç”Ÿï¼Œå¯¹æ•´ä¸ªè®²è§£è¿›è¡Œç»¼åˆæ€§çš„æ·±åº¦åˆ†æï¼Œæå‡º2-4ä¸ªé‡è¦é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. æ•´ä½“é€»è¾‘ç»“æ„æ˜¯å¦å®Œæ•´
2. å…³é”®æ¦‚å¿µæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…
3. æ˜¯å¦ç¼ºå°‘é‡è¦çš„ä¾‹å­æˆ–åº”ç”¨
4. çŸ¥è¯†ç‚¹ä¹‹é—´çš„å…³è”æ€§
5. éœ€è¦æ·±åº¦è®¨è®ºçš„æ ¸å¿ƒé—®é¢˜

ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "id": "final1",
    "type": "question",
    "title": "æ ¸å¿ƒæ¦‚å¿µç¡®è®¤",
    "content": "å…·ä½“çš„æ·±åº¦é—®é¢˜",
    "needsResponse": true
  }},
  {{
    "id": "final2", 
    "type": "clarification",
    "title": "é€»è¾‘è¿æ¥",
    "content": "éœ€è¦æ¾„æ¸…çš„é€»è¾‘å…³ç³»",
    "needsResponse": false
  }}
]

æ³¨æ„ï¼š
- è¿™æ˜¯æœ€ç»ˆåˆ†æï¼Œå¯ä»¥æå‡ºéœ€è¦è¯¦ç»†å›ç­”çš„æ·±åº¦é—®é¢˜(needsResponse: true)
- å…³æ³¨æ•´ä½“æ€§å’Œæ·±åº¦ï¼Œè€Œä¸æ˜¯ç»†èŠ‚
- typeå¯ä»¥æ˜¯: question(ç–‘é—®), concern(æ‹…å¿§), clarification(æ¾„æ¸…), praise(å¥½è¯„)
"""

    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        ai_response = response.text
        
        try:
            return json.loads(ai_response)
        except json.JSONDecodeError:
            return [
                {
                    "id": "final_default",
                    "type": "question",
                    "title": "æ•´ä½“ç†è§£ç¡®è®¤",
                    "content": "æ€»çš„æ¥è¯´è®²è§£å¾ˆå¥½ï¼Œèƒ½å¦æ€»ç»“ä¸€ä¸‹æ ¸å¿ƒè¦ç‚¹ï¼Ÿ",
                    "needsResponse": True
                }
            ]
            
    except Exception as e:
        print(f'æœ€ç»ˆåˆ†æAPIè°ƒç”¨å¤±è´¥: {e}')
        return [
            {
                "id": "final_error",
                "type": "praise",
                "title": "è®²è§£å®Œæˆ",
                "content": "æ„Ÿè°¢æ‚¨çš„è¯¦ç»†è®²è§£ï¼",
                "needsResponse": False
            }
        ]

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug_mode = os.getenv('FLASK_ENV') == 'development'
    
    print(f'ğŸš€ è´¹æ›¼å­¦ä¹ åŠ©æ‰‹è¿è¡Œåœ¨ http://localhost:{port}')
    app.run(host='0.0.0.0', port=port, debug=debug_mode)